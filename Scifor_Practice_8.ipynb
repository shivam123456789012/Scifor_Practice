{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc91314b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90008b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tfds.load(\"imdb_reviews\",as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f6113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset=data[\"train\"],data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e95ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_dataset=train_dataset.shuffle(10000)\n",
    "train_dataset=train_dataset.batch(batch_size)\n",
    "test_dataset=test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5484c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " b'Not sure why this movie seems to have gotten such rave reviews.<br /><br />While watching \"Bang\" one night on TV, I found myself bored by the nonsensical, random plot which was occurring on screen. The entire movie seems to be nothing more than an exercise in meaningless, artsy-fartsy self-indulgence on the part of the filmmaker. The fact that the director/writer goes by a one name moniker only reinforces this sense of pretentiousness. <br /><br />Those interested in indie flicks would be better off looking for something better written and dare I say, more entertaining than this complete waste of time.'\n",
      "\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "exm,label=next(iter(train_dataset))\n",
    "print(\"Text:\\n\",exm.numpy()[0])\n",
    "print(\"\\nlabel: \",label.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff76afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  b'Not sure why this movie seems to have gotten such rave reviews.<br /><br />While watching \"Bang\" one night on TV, I found myself bored by the nonsensical, random plot which was occurring on screen. The entire movie seems to be nothing more than an exercise in meaningless, artsy-fartsy self-indulgence on the part of the filmmaker. The fact that the director/writer goes by a one name moniker only reinforces this sense of pretentiousness. <br /><br />Those interested in indie flicks would be better off looking for something better written and dare I say, more entertaining than this complete waste of time.'\n",
      "encoded:  [  22  243  134   11   18  181    6   26 1772  136 5152    1   13  131\n",
      "  147 4745   29  311   21  244   10  249  532 1072   33    2 4720 1473\n",
      "  114   60   14    1   21  293    2  417   18  181    6   28  158   52\n",
      "   71   34 3416    8 4022    1    1   21    2  171    5    2 1565    2\n",
      "  185   12    2    1  261   33    4   29  398    1   61    1   11  278\n",
      "    5    1   13   13  144  899    8 2764 1517   59   28  125  127  280\n",
      "   16  140  125  420    3 3302   10  130   52  441   71   11  573  423\n",
      "    5   62]\n",
      "decoded:  not sure why this movie seems to have gotten such rave [UNK] br while watching bang one night on tv i found myself bored by the nonsensical random plot which was [UNK] on screen the entire movie seems to be nothing more than an exercise in meaningless [UNK] [UNK] on the part of the filmmaker the fact that the [UNK] goes by a one name [UNK] only [UNK] this sense of [UNK] br br those interested in indie flicks would be better off looking for something better written and dare i say more entertaining than this complete waste of time\n"
     ]
    }
   ],
   "source": [
    "encoder=tf.keras.layers.TextVectorization(max_tokens=9000)\n",
    "encoder.adapt(train_dataset.map(lambda text, _:text))\n",
    "\n",
    "vocabulary=np.array(encoder.get_vocabulary())\n",
    "\n",
    "original_text=exm.numpy()[0]\n",
    "encoded_text=encoder(original_text).numpy()\n",
    "decoded_text=\" \".join(vocabulary[encoded_text])\n",
    "\n",
    "print(\"original: \",original_text)\n",
    "print(\"encoded: \",encoded_text)\n",
    "print(\"decoded: \",decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b6ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 64)          576000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 128)         66048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687489 (2.62 MB)\n",
      "Trainable params: 687489 (2.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    encoder,tf.keras.layers.Embedding(\n",
    "    len(encoder.get_vocabulary()),64,mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(64,return_sequences=True)),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb9608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9296322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UJJWAL GARG\\Desktop\\by\\ana\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1684s 2s/step - loss: 0.3776 - accuracy: 0.8203 - val_loss: 0.3690 - val_accuracy: 0.8101\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 2264s 3s/step - loss: 0.2253 - accuracy: 0.9072 - val_loss: 0.3032 - val_accuracy: 0.8690\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 1456s 2s/step - loss: 0.1489 - accuracy: 0.9436 - val_loss: 0.3569 - val_accuracy: 0.8428\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 1524s 2s/step - loss: 0.0905 - accuracy: 0.9659 - val_loss: 0.3986 - val_accuracy: 0.8502\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_dataset,epochs=4,validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b112dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "-1.5923638\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(np.array([\"12th fail movie is fantastic\"]))\n",
    "print(*predictions[0])\n",
    "\n",
    "if predictions[0]>0:\n",
    "    print(\"positive\")\n",
    "    \n",
    "else:\n",
    "    print(\"negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
